{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Assignment2_RL_Team39.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbcjompGqWi2"
      },
      "source": [
        "# Reinforcement Learning\n",
        "\n",
        "**Grid World environment with DQN**\n",
        "\n",
        "\\- Vaibhav Rao\n",
        "  50375332\n",
        "\n",
        "\\- Kunal Beniwal\n",
        "  50381672\n",
        "\n"
      ],
      "id": "MbcjompGqWi2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70506397",
        "outputId": "70265144-9a91-4178-945d-96d11fb5660b"
      },
      "source": [
        "! pip install gym"
      ],
      "id": "70506397",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb9TUC9-r-nc"
      },
      "source": [
        "#### Imports"
      ],
      "id": "Eb9TUC9-r-nc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a916ad08"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym import spaces\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from collections import deque"
      ],
      "id": "a916ad08",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d33f887"
      },
      "source": [
        "class GridEnvironment(gym.Env):\n",
        "    metadata = { 'render.modes': [] }\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.observation_space = spaces.Discrete(16)\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "        self.max_timesteps = 20\n",
        "        \n",
        "    def reset(self):\n",
        "        self.timestep = 0\n",
        "        self.agent_pos = [0, 0]\n",
        "        self.goal_pos = [3, 3]\n",
        "        self.trap = [2, 0]\n",
        "        self.food = [1,2]\n",
        "        self.state = np.zeros((4,4))\n",
        "        self.state[tuple(self.agent_pos)] = 1\n",
        "        self.state[tuple(self.goal_pos)] = 0.5\n",
        "        self.state[tuple(self.trap)] = 0.3\n",
        "        self.state[tuple(self.food)] = 0.1\n",
        "        #observation = self.state.flatten()\n",
        "        observation = self.agent_pos[0]*4 + self.agent_pos[1]\n",
        "        return observation\n",
        "    \n",
        "    def step(self, action):\n",
        "        self.prev_state = list(self.agent_pos)\n",
        "        # Move DOWN\n",
        "        if action == 0:\n",
        "          self.agent_pos[0] += 1\n",
        "        # Move UP\n",
        "        if action == 1:\n",
        "          self.agent_pos[0] -= 1\n",
        "        # Move Right\n",
        "        if action == 2:\n",
        "          self.agent_pos[1] += 1\n",
        "        # Move Left\n",
        "        if action == 3:\n",
        "          self.agent_pos[1] -= 1\n",
        "          \n",
        "        self.agent_pos = np.clip(self.agent_pos, 0, 3)\n",
        "        self.state = np.zeros((4,4))\n",
        "        self.state[tuple(self.agent_pos)] = 1\n",
        "        self.state[tuple(self.goal_pos)] = 0.5\n",
        "        self.state[tuple(self.trap)] = 0.3\n",
        "        self.state[tuple(self.food)] = 0.1\n",
        "        # observation = self.state.flatten()\n",
        "        observation = self.agent_pos[0]*4 + self.agent_pos[1]\n",
        "        \n",
        "        reward = 0\n",
        "        if (self.agent_pos == self.goal_pos).all():\n",
        "          reward = 30\n",
        "        if (self.agent_pos == self.trap).all():\n",
        "          reward = -5\n",
        "        if (self.agent_pos == self.food).all():\n",
        "          reward = 2\n",
        "        if (self.agent_pos == self.prev_state).all():\n",
        "          reward = -1\n",
        "        \n",
        "        \n",
        "        self.timestep += 1\n",
        "        done = True if self.timestep >= self.max_timesteps else False\n",
        "        info = {}\n",
        "        \n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def step_stochastic(self, action):\n",
        "        self.prev_state = list(self.agent_pos)\n",
        "        self.same_pos_reward = True\n",
        "        # Move DOWN (Stochastic with 0.1 probability of not moving)\n",
        "        if action == 0:\n",
        "          stoch_step = np.random.choice([1, 0], p=[0.9,0.1])\n",
        "          self.agent_pos[0] += stoch_step\n",
        "          if not stoch_step:\n",
        "            self.same_pos_reward = False\n",
        "        # Move UP\n",
        "        if action == 1:\n",
        "          self.agent_pos[0] -= 1\n",
        "        # Move Right\n",
        "        if action == 2:\n",
        "          self.agent_pos[1] += 1\n",
        "        # Move Left (Probability of not taking a left in this action = 0.3)\n",
        "        if action == 3:\n",
        "          stoch_step = np.random.choice([1, 0], p=[0.7,0.3])\n",
        "          self.agent_pos[1] -= stoch_step\n",
        "          if not stoch_step:\n",
        "            self.same_pos_reward = False\n",
        "\n",
        "        self.agent_pos = np.clip(self.agent_pos, 0, 3)\n",
        "        self.state = np.zeros((4,4))\n",
        "        self.state[tuple(self.agent_pos)] = 1\n",
        "        self.state[tuple(self.goal_pos)] = 0.5\n",
        "        self.state[tuple(self.trap)] = 0.3\n",
        "        self.state[tuple(self.food)] = 0.1\n",
        "        # observation = self.state.flatten()\n",
        "        observation = self.agent_pos[0]*4 + self.agent_pos[1]\n",
        "        \n",
        "        reward = 0\n",
        "        if (self.agent_pos == self.goal_pos).all():\n",
        "          reward = 10\n",
        "        if (self.agent_pos == self.trap).all():\n",
        "          reward = -5\n",
        "        if (self.agent_pos == self.food).all():\n",
        "          reward = 2\n",
        "        if (self.agent_pos == self.prev_state).all() and self.same_pos_reward:\n",
        "          reward = -1\n",
        "        \n",
        "        \n",
        "        self.timestep += 1\n",
        "        done = True if self.timestep >= self.max_timesteps else False\n",
        "        info = {}\n",
        "        \n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        plt.imshow(self.state)\n",
        "\n",
        "    def run(self, agent):\n",
        "      state = self.reset()\n",
        "      self.R=0\n",
        "      while True:            \n",
        "        self.render()\n",
        "        action = agent.act(state)\n",
        "        nextState, reward, done, info = self.step(action)\n",
        "        if done: # terminal state\n",
        "            nextState = None\n",
        "        agent.remember(state, action, reward, nextState, done)\n",
        "        agent.replay(32)\n",
        "\n",
        "        state = nextState\n",
        "        self.R = self.R + reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "      print(\"Total reward:\", self.R)\n",
        "      return self.R\n"
      ],
      "id": "5d33f887",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "83b55849",
        "outputId": "05fa176e-79e1-4ae1-9bce-5e70aef4c93b"
      },
      "source": [
        "env = GridEnvironment()\n",
        "obs = env.reset()\n",
        "env.render()"
      ],
      "id": "83b55849",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsbi-aCHcYho"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, env):\n",
        "    self.env = env\n",
        "    self.observation_space = env.observation_space.n\n",
        "    self.action_space = env.action_space.n\n",
        "    self.model = self.buildModel()\n",
        "    self.memory = deque(maxlen=1500)\n",
        "    self.lr = 0.001\n",
        "    self.gamma = 0.95\n",
        "    self.epsilon = 1.0\n",
        "\n",
        "  def buildModel(self):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(24, input_shape=(self.observation_space,), activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(self.action_space, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
        "    return model\n",
        "\n",
        "  def predictState(self, state):\n",
        "    #print(\"pred\",state)\n",
        "    #s = np.zeros((self.observation_space,), dtype=int)\n",
        "    #s[int(state)]=1\n",
        "    print(\"Predict Shape :\",state.shape)\n",
        "    return self.model.predict(state,)\n",
        "\n",
        "  def act(self, state):\n",
        "    print(\"act\",state)\n",
        "    s = np.zeros((self.observation_space,1), dtype=int)\n",
        "    s[state]=1\n",
        "    print(\"act\",state)\n",
        "    if np.random.uniform(0,1) <= self.epsilon:\n",
        "      return np.random.choice(self.action_space)\n",
        "    else:\n",
        "      return np.argmax(self.predictState(s))\n",
        "\n",
        "  def sample(self,n):\n",
        "    n = min(n, len(self.memory))\n",
        "    return random.sample(self.memory, n)\n",
        "\n",
        "  def remember(self, state, action, reward, next_state, done):\n",
        "    self.memory.append((state, action, reward, next_state, done))\n",
        "    if self.epsilon > 0.1:\n",
        "        self.epsilon *= 0.9\n",
        "    return self.epsilon\n",
        "    \n",
        "\n",
        "  def replay(self, batch_size):\n",
        "    if len(self.memory) < batch_size:\n",
        "      return\n",
        "    sample_batch = random.sample(self.memory, batch_size)\n",
        "    for state, action, reward, next_state, done in sample_batch:\n",
        "        target = reward\n",
        "        if not done:\n",
        "          print(\"replay\",next_state)\n",
        "          target = reward + self.gamma * np.amax(self.model.predict(next_state))\n",
        "        print(\"replay\",next_state)\n",
        "        target_f = self.model.predict(state)\n",
        "        target_f[action] = target\n",
        "        self.model.fit(state, target_f, epochs=1, verbose=0)\n"
      ],
      "id": "Dsbi-aCHcYho",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JG23XT0RxsKy",
        "outputId": "7161b77f-7701-483e-a098-4aad40e0d919"
      },
      "source": [
        "env = GridEnvironment()\n",
        "\n",
        "states  = env.observation_space.n\n",
        "actions = env.action_space.n\n",
        "agent = Agent(env)\n",
        "\n",
        "episodes=2000\n",
        "for i in range(episodes):\n",
        "    r = env.run(agent)\n",
        "    reward.append(r)\n"
      ],
      "id": "JG23XT0RxsKy",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "act 0\n",
            "act 0\n",
            "act 0\n",
            "act 0\n",
            "act 1\n",
            "act 1\n",
            "act 5\n",
            "act 5\n",
            "act 9\n",
            "act 9\n",
            "Predict Shape : (16, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-a62bcba892f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mreward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-41ed820ea921>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mnextState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# terminal state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-0ee9e3ee6e7a>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-0ee9e3ee6e7a>\u001b[0m in \u001b[0;36mpredictState\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#s[int(state)]=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predict Shape :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_39 is incompatible with the layer: expected axis -1 of input shape to have value 16 but received input with shape (None, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}